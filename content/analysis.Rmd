---
title: Analysis
description:
toc: true
featuredVideo:
featuredImage: https://upload.wikimedia.org/wikipedia/commons/7/77/Pebbleswithquarzite.jpg
draft: false
---

This comes from the file `content/analysis.Rmd`.

We describe here our detailed data analysis.

##Section 1: Motivation of Data Analysis
As the United States population grows and develops, there will be a greater need for information on the general health of the nation. Our initial plan was to assess health trends over the course of time (more specifically, two decades worth of data from the National Health and Nutrition Examination Survey program). We first used diastolic and systolic blood pressures as a means of assessing general health. Later on, we ended up using Mean Arterial Pressure (MAP) instead as it provided us a way to combine both diastolic and systolic blood pressures into one value. This made the overall analysis more clean and compact. We also wanted to see how impactful ethnicity/race is on MAP; an initial exploration of the relationship between race and Thus, the variables that we are most interested in are race/ethnicity, MAP, and time (in years). 

After summarizing these relationships together, we can then determine how impactful race/ethnicity is on MAP compared to other predictors of health. As a result, we generated multiple tables and plots of health variables with covariables to profile each relationship. Aside from these other predictors for health, we also plan on introducing a secondary dataset for government expenditure on general health. 

Some questions we wanted to answer through our analysis:
Does government expenditure have a significant impact on general health?
How much do these other factors affect health variables?
Which of these predictors of health has the greatest impact on health?
How do health trends change over time?

##Section 2: Variable Analysis
```{r, include=FALSE}
# load modelData and rename variables
suppressPackageStartupMessages(library(tidyverse))
library(modelr)
library(caret)
suppressPackageStartupMessages(library(broom))
library(MASS)
library(car)
library(grid)

print(getwd())
MAPvsEx <- read_csv(here::here("dataset/MAPvsEx.csv"))
modelData <- read_csv(here::here("dataset/modelData.csv"))
modelData <- rename(modelData, c("Ethnicity" = "RIDRETH1",
                                 "Age" = "RIDAGEYR", 
                                 "Gender" = "RIAGENDR", 
                                 "Blood Pressure" = "BPQ050A", 
                                 "Hypertension" = "HTN"))
```

To investigate the 
```{r year_boxplot, warning=FALSE, message=FALSE, echo = FALSE}
modelData %>% ggplot(aes(x = factor(Year), y = MAP)) +
  geom_boxplot() +
  stat_smooth(method = "lm", se = FALSE) +
  labs(title = "Mean Arterial Pressure (MAP) by Year", x = "Year", y = "Mean Arterial Pressure") +
  coord_flip()
```

```{r age_lineplot, warning=FALSE, message=FALSE, echo = FALSE }
age_plot <- ggplot(modelData, aes(x=Age, y=MAP)) + 
  geom_smooth(method = "gam") 
age_plot
```



```{r data_split, include=FALSE}
# separate data into training and testing sets
set.seed(42)
training.samples <- 
  createDataPartition(modelData$MAP, p = 0.7, list = FALSE)
train.modelData  <- modelData[training.samples, ]
test.modelData <- modelData[-training.samples, ]
```


```{r MLR_summary}
# creating multiple linear regression model to predict MAP
model <- lm(MAP ~ Ethnicity + factor(Year) + Age + Gender, data = train.modelData)
summary(model) 
```


```{r, warning=FALSE, message=FALSE, include = FALSE}
# print out the coefficients and significant levels of each predictors
train.modelData %>% lm(formula = MAP ~ Ethnicity + factor(Year) + Age + Gender) %>% 
  broom::tidy() %>%
  knitr::kable(format = "markdown")
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
grid <- train.modelData %>% data_grid(Ethnicity, Year, Age, Gender) %>% 
 gather_predictions(model, .model = "lm")

# Make predictions
predictions <- model %>% predict(test.modelData)
# Model performance
data.frame(
  RMSE = RMSE(predictions, test.modelData$MAP),
  R2 = R2(predictions, test.modelData$MAP)
)
```



```{r, warning=FALSE, message=FALSE}
# load package to perform AIC
vif(model)
```


```{r, warning=FALSE, message=FALSE}
# perform AIC to eliminate insignificant variables
stepAIC(model, direction ="both")
```


```{r}
# multiple linear regression model with interaction terms 
model_interaction_eth <- lm(MAP ~ Ethnicity + factor(Year) + Age + Gender +  
                        Ethnicity*Age, data = train.modelData)
model_interaction_gd <- lm(MAP ~ Ethnicity + factor(Year) + Age + Gender +  
                        Gender*Age, data = train.modelData)
model_interaction_both <- lm(MAP ~ Ethnicity + factor(Year) + Age + Gender +  
                        Gender*Age + Ethnicity*Age, data = train.modelData)
summary(model_interaction_eth)
summary(model_interaction_gd)
summary(model_interaction_both)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
gender_ia_plot <- ggplot(train.modelData, aes(Age, MAP)) + geom_point(aes(color = Gender)) 
ethn_ia_plot <- ggplot(train.modelData, aes(Age, MAP)) + geom_point(aes(color = Ethnicity))

grid.newpage()
grid.draw(rbind(ggplotGrob(gender_ia_plot), ggplotGrob(ethn_ia_plot), size = "last"))
```


```{r, echo=FALSE}
# Make predictions
predictions_interaction <- model_interaction_both %>% predict(test.modelData)
# Model performance
data.frame(
  RMSE = RMSE(predictions_interaction, test.modelData$MAP),
  R2 = R2(predictions_interaction, test.modelData$MAP)
)
```



```{r}
vif(model_interaction_both)
```


```{r, warning=FALSE, message=FALSE}
# perform AIC to eliminate insignificant variables
stepAIC(model_interaction_both, direction ="both")
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
grid_2_eth <- train.modelData %>% data_grid(Ethnicity, Year, Age, Gender) %>% # needs both variables
 gather_predictions(model, model_interaction_eth, .model = "lm")

grid_2_gd <- train.modelData %>% data_grid(Ethnicity, Year, Age, Gender) %>% # needs both variables
 gather_predictions(model, model_interaction_gd, .model = "lm")

ggplot(modelData, aes(Age, MAP, color = Gender)) + 
 geom_smooth(aes(y = grid_2_gd$pred), data = grid_2_gd, size = 1) +
 facet_wrap(~ lm)

ggplot(modelData, aes(Age, MAP, color = Ethnicity)) + 
 geom_smooth(aes(y = grid_2_eth$pred), data = grid_2_eth, size = 1) +
 facet_wrap(~ lm)
```





```{r scatter_plot_gd, echo=FALSE}
train.modelData %>%
  filter(Year == "2018") %>%
  ggplot(aes(Age, MAP)) + geom_point(aes(color = Gender)) 
```



```{r scatter_plot_eth, echo=FALSE}
train.modelData %>%
  filter(Year == "2018") %>%
  ggplot(aes(Age, MAP)) + geom_point(aes(color = Ethnicity)) 
```

```{r, echo = FALSE}
train.modelData %>% ggplot(aes(x = MAP, y = ..density..)) +
  geom_histogram(binwidth = 2, colour= "black", fill= "lightblue") +
  geom_vline(aes(xintercept = median(MAP, na.rm = TRUE)),color="black", linetype="dashed", size=1) +
  geom_density(color = "red") +
  labs(title = "Histogram of Mean Arterial Pressure (MAP)", x = "Mean Arterial Pressure (MAP) (mmHg)", 
       y = "Density") 
```



```{r corr_matrix, warning=FALSE, message=FALSE, echo = FALSE}
# correlation matrix
library(ggcorrplot)
model.matrix(~0+., data=modelData) %>% 
  cor(use="pairwise.complete.obs") %>% 
  ggcorrplot(show.diag = F, type="lower", lab=TRUE, lab_size=2)
```





```{r MAPvsEx_sidebyside, warning=FALSE, message=FALSE, echo = FALSE}
plot_govExp <- ggplot(data = MAPvsEx,aes(x=Year, y = GovernmentHealthExpenditure)) + 
         geom_point()
plot_medMAP <- ggplot(data = MAPvsEx,aes(x=Year, y = MedianMAP)) + 
         geom_point()

grid.newpage()
grid.draw(rbind(ggplotGrob(plot_govExp), ggplotGrob(plot_medMAP), size = "last"))
```


```{r MapvsEx_reg, warning=FALSE, message=FALSE, echo = FALSE}
MAPEx_model <- lm(MedianMAP ~ GovernmentHealthExpenditure, data = MAPvsEx)
summary(MAPEx_model)
ggplot(MAPvsEx, aes(x = GovernmentHealthExpenditure, y = MedianMAP)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red")
```


```{r Ex_year_line, warning=FALSE, message=FALSE, echo = FALSE}
ggplot(MAPvsEx, aes(x = Year, y = GovernmentHealthExpenditure)) + 
  geom_point() +
  stat_smooth(method = "lm", col = "blue")
```


## Note on Attribution

If you are directly quoting from a source, please make that clear. You can show quotes using `>` like this

```
> To be or not to be.
```

> To be or not to be.

Also, make sure to provide a link or citation to where you are quoting from.

-------


## Rubric: On this page

you will


* Introduce what motivates your Data Analysis (DA)
  * Which variables and relationships are you most interested in?
  * What questions are you interested in answering?
* Breadth of the DA
  * Make sure that you ask enough initial questions to explore the different variables in your data.
  * i.e. Do you explore more than just one or two variables? Do you explore a few different relationships or many?
* Depth of the DA
  * When you answer one question, usually more questions arise as well. 
  * The depth of the DA is about coming up with and exploring the answers to these questions, often iterating the process a few times.
* Modeling and Inference 
  * You should also include some kind of formal statistical model and/or inference. This could be a linear regression, logistic regression, hypothesis testing etc.
  * Explain the techniques you used for validating your results.
  * Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
* Explain the flaws and limitations of your analysis
  * Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions? ...
* Clarity Figures
  * Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
  * Each figure should provide a key insight. Too many figures or other data summaries can detract from this.
* Clarity of Explanations
  * Do you introduce why you are doing each analysis?
  * How well do you explain each figure/result?
  * Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
* Organization and cleanliness.
  * Make sure to remove excessive warnings, use clean easy-to-read code, organize with sections or multiple pages, use bullets, etc.
  
  
**NOTE**: Your Data Analysis can be broken up into multiple pages if that helps with your organization.


