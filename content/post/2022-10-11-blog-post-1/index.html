---
title: Blog Post 1
author: Daniel Sussman
date: '2022-10-12'
slug: []
categories: []
tags: []
description: ~
toc: yes
authors: []
series: []
lastmod: '2022-10-11T16:41:03-04:00'
featuredVideo: ~
featuredImage: ~
---


<div id="TOC">

</div>

<p>**All the Links will be added at the end of the paragraph</p>
<pre><code>The first data design we will be proposing is NHANES, National Health and Nutrition Examination Survey. The purpose of the employment of this data set is to assess overall health of adults and children in the US using both interviews and physical examinations. The main collector/conductor of the data is from offical CDC, Center for Disease Control and Prevention, was the priority purpose was to check the health statistics for whole of US. To be specific, a sample of 5,000 people was intended to represent the population, as NHANES interview includes demographic, socioeconomic, dietary, and health-related questions. The examination component consists of medical, dental, and physiological measurements, as well as laboratory tests administered by highly trained medical personnel, so it can be used to determine prevalence of diseases and disease risk factors. Relationship between nutrition status and association with disease prevention could be found as well, enabling to track national standing of general health. Moreover, it provides physiological measurements such as height, BMI, and other adjuvant informational health-related variables.
NHANES started collecting their data around 1999-2000, making about 12 datasets available. As mentioned above, there are 5,000 individuals interviewed and examined, categorized by 5 different sections: demographics, diet, examination, laboratory, and questionnaire data. Within each of these categories is roughly 10-30 different datasets, bringing the number of total columns accessible to be more than 1,000 different variables. With these extensive, detailed categories, our team is able to ask various questions about health. On behalf of that variety, our team will analyze health trends over the past 10 year, focusing on the trend over course, especially during the pandemic. Our team still faces some challenges as well, as the data is based on individual datum (row). In other words, there will be difficulty in combining secondary data. This can be possibly resolved through discovering some kind of primary variable/joining protocol from a quick literature search.</code></pre>
<p>Link: <a href="https://wwwn.cdc.gov/nchs/nhanes/Default.aspx" class="uri">https://wwwn.cdc.gov/nchs/nhanes/Default.aspx</a></p>
<hr />
<pre><code>Interestingly, our team was able to find another interesting data with a similar health topic, but with quite a different approach. SAMHSA, Substance Abuse &amp; Mental Health Data Archive, provides mental health client-level data to the public, offered by the U.S. Department of Health and Human Services (HHS). Not only it focuses on the general public health status, it provides specific information on mental health diagnoses and treatment services, outcomes, and patient demographics. A single data set has an average of 6 million rows with 39 columns, and SAMHSA has from 2013 to 2019. </code></pre>
<p>Link: <a href="https://www.datafiles.samhsa.gov/data-sources" class="uri">https://www.datafiles.samhsa.gov/data-sources</a> Link (2019 Data): <a href="https://www.datafiles.samhsa.gov/dataset/mental-health-client-level-data-2019-mh-Cld-2019-" class="uri">https://www.datafiles.samhsa.gov/dataset/mental-health-client-level-data-2019-mh-Cld-2019-</a> ds0001</p>
<hr />
<pre><code>Not only general health issues, our team has great interest in natural disasters. Among those disasters, we found an excellent dataset about wildfires/forest fires in the United States, provided in Kaggle.com. Officially sponsored by government data collection: Forest Service Research Data, our team was able to explore the frequency of (wild)fires over the years. Shown in the title of the dataset, it has about 1.88 million wildfire cases as a spatial database occurred throughout the country. Along with about 1 million cases, it has 40 columns. However unfortunately, most columns are just character values or subordinate district section names, etc, unable to use them with efficiency. The data starts from the year of 1992, compiled from US federal, state, and local reporting systems. As the data is well-organized on the basis of region, it was easy to see the proneness of each district, as well as time, date, and size of the fire, able to potentially predict the cause of the wildfire based on variables. As a status quo, we were unable to completely load in the data completely and it was a little challenging to get the data in CSV format in the first place. Moreover, since this data records only the &quot;results&quot; of the wild fires, our team must obtain secondary data in order to argue the correlation between natural wildfires and climate change. Through this, we hope to develop an algorithm to predict future wildfires occurring in the US. However, it would not be easy to completely include primary and subordinate data, with so many datasets as well as fractionated district categories into one. Finding additional information that is not already provided might prove to be difficult given how specific the data is for location/region (i.e. finding temperature/humidity data for a specific region for the time range for this dataset might not be available). In conclusion, a general summary with this dataset is possible but it might take away the predicting power that we hoped to achieve.</code></pre>
<p>Link: <a href="https://www.kaggle.com/datasets/rtatman/188-million-us-wildfires?resource=download" class="uri">https://www.kaggle.com/datasets/rtatman/188-million-us-wildfires?resource=download</a></p>
