% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Data},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Data}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\#\#Data Summary and Origin

For our project, we set our sights on the National Health and Nutrition
Examination Survey (NHANES) dataset to help us profile different health
trends. NHANES is a program designed and conducted by the National
Center for Health Statistics (NCHS), a branch of the Center of Disease
Control (CDC). The program has surveyed around 5000 people as a
nationally representative sample every year since 1999. The purpose of
this study is to assess the general health, nutritional status, and
prevalence/risk factors of disease in the population of adults and
children in the United States through interview questions and laboratory
exams. Interview questions seek to gather information related to
demographic, socioeconomic, dietary, and health-related information. The
examination component consists of medical, dental, and physiological
measurements, as well as laboratory tests administered by medical
personnel. With this, we are able to find trends from health datasets
throughout the last two decades.

To complement the health data provided by NHANES, we've decided to
include a secondary dataset related to the allocation of United States
government funds to healthcare from xthe World Bank website. The data is
collected by the Development Data Group for the purpose of meeting
demands of high quality statistical data for analysts around the world.

\#\#Data Files and Relevant Variables

Our group plans on using every NHANES dataset from 1999-2018 (ten
collection cycles in total). For each data collection cycle, we used the
singular dataset in the ``Demographics Data'' tab and the ``Blood
Pressure'' dataset under the ``Examination Data'' tab. The data from the
World Bank can be found in the website linked in the previous section.
The dataset used by our group can be found on the right side of the
webpage; simply click ``CSV'' under the section called ``Download.''

The blood pressure dataset in NHANES consists of information related to
blood pressure measurements and the manner in which they were taken such
as what arm was used and substances consumed prior to examination. The
specific variables used by our group were the first three readings for
systolic and diastolic measurements of blood pressure named
``BPXSY1(2,3)'' and ``BPXDI1(2,3).'' The demographics data in NHANES
consists of data related to individual demographics like education
level, race, age, income, etc. Our models seek to specifically explore
race (RIDRETH1), age (RIDAGEYR), and gender (RIAGENDR) as predictors of
blood pressure.

The World Bank dataset consists of hundreds of variables related to the
expenditures of the United States government. Each row is a variable,
and each column is an observation within a given year, thus
necessitating some cleaning. The specific row variable that we will use
in our analysis is ``SH.XPD.GHED.GE.ZS,'' which lists the percent of
government funds allocated toward general health by year.

\#\#Data Cleaning

A link to our load\_and\_clean\_data.R file can be found here (this file
is currently incomplete and subject to major changes). The NHANES data
is only available in the SAS data format .XPT; thus, the ``read\_xpt()''
function from the ``haven'' package was necessary to load the dataset
into the R environment. The data was then written to a CSV file using
``write\_csv()'' from the ``tidyverse'' package for a permanent
conversion to a data file type more commonly used by R. The datasets
were then loaded into the R environment using ``read\_csv().''

For the first step in data cleaning, the mean diastolic and systolic
blood pressures of each individual was calculated and saved to a
variable named ``MeanDia'' and ``MeanSys'' respectively. Then, a new
variable called ``MAP'' was created using the formula MAP = MeanDia +
((MeanSys-MeanDia)/3) (not yet included in R file, but will be for final
analyses). Following the creation of these variables, the BP data and
demographics data was combined for each year using an ``inner\_join()''
by ``SEQN.'' Following this joining, a new column called ``Year'' was
added to each dataset corresponding to the year in which the data was
collected. Lastly, each data frame corresponding to a cycle of NHANES
was combined into a single data frame using ``bind\_rows()'' that was
then written to a CSV file. (will include code output in the final
version here, but not yet complete).

The health expenditure dataset was loaded into the R environment using
``read\_csv()'' and ``filtered'' to include only the row corresponding
to ``SH.XPD.GHED.GE.ZS.'' To properly orient the dataset,
``pivot\_longer()'' was used with values to ``Health\_Expenditure'' and
names to ``Year.'' The dataset was further ``filtered'' to include only
the years 1999-2018, the years of NHANES collection used in our
analysis. NHANES cycles usually occur over two years, so the values for
expenses were averaged over every two years (i.e.~1999 and 2000 were
averaged, 2001 and 2002 were averaged. etc.). To prepare the NHANES
dataset for joining with the expenditure dataset, the NHANES dataset was
summarized by the median MAP for each cycle. The expenditure dataset was
then joined to the NHANES dataset by year. (once again, code output will
be included here, but it's not finished yet).

\end{document}
